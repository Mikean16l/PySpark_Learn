{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-libs-and-load-data\" data-toc-modified-id=\"Import-libs-and-load-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import libs and load data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Split-data-columns-by-comma\" data-toc-modified-id=\"Split-data-columns-by-comma-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Split data columns by comma</a></span></li></ul></li><li><span><a href=\"#Sampling-data\" data-toc-modified-id=\"Sampling-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sampling data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Method-1-for-sampling\" data-toc-modified-id=\"Method-1-for-sampling-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Method 1 for sampling</a></span></li><li><span><a href=\"#Method-2-for-sampling\" data-toc-modified-id=\"Method-2-for-sampling-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Method 2 for sampling</a></span></li></ul></li><li><span><a href=\"#Get-partitions\" data-toc-modified-id=\"Get-partitions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Get partitions</a></span></li><li><span><a href=\"#Reparation\" data-toc-modified-id=\"Reparation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Reparation</a></span></li><li><span><a href=\"#zipWithIndex\" data-toc-modified-id=\"zipWithIndex-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>zipWithIndex</a></span><ul class=\"toc-item\"><li><span><a href=\"#View-row-with-index\" data-toc-modified-id=\"View-row-with-index-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>View row with index</a></span></li><li><span><a href=\"#Remove-header\" data-toc-modified-id=\"Remove-header-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Remove header</a></span></li></ul></li><li><span><a href=\"#Group-by-(reduceByKey)\" data-toc-modified-id=\"Group-by-(reduceByKey)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Group by (reduceByKey)</a></span></li><li><span><a href=\"#Join\" data-toc-modified-id=\"Join-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Join</a></span></li><li><span><a href=\"#Union\" data-toc-modified-id=\"Union-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Union</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark RDD HW1\n",
    "                       by Mike\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import sql, SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this to build rdd or the second method\n",
    "scc = sql.SparkSession.builder.appName('Rdd1')\\\n",
    "                    .config('spark.executer.memory','9g').getOrCreate()\n",
    "sc = scc.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or using this method\n",
    "\n",
    "# The first thing a Spark program must do is to create a SparkContext object, \n",
    "# which tells Spark how to access a cluster. To create a SparkContext you first\n",
    "# need to build a SparkConf object that contains information about your \n",
    "# application.\n",
    "appName = 'HW_1'\n",
    "master = 'local'\n",
    "conf = SparkConf().setAppName(appName).setMaster(master)\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if restart needed\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Load the departure delays file and split it by comma (,). Call it flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "departuredelays = sc.textFile('data/departuredelays.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data columns by comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = departuredelays.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['date', 'delay', 'distance', 'origin', 'destination'],\n",
       " ['01011245', '6', '602', 'ABE', 'ATL'],\n",
       " ['01020600', '-8', '369', 'ABE', 'DTW']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling data\n",
    "Provide a sample based on 0.001% the flights RDD data specific to the fourth column (origin city of flight) without replacement (False) using random seed of 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['01311915', '0', '279', 'ATL', 'SDF'],\n",
       " ['01101400', '25', '778', 'DEN', 'MDW'],\n",
       " ['01032040', '51', '245', 'DFW', 'LBB'],\n",
       " ['01011403', '28', '1192', 'DFW', 'EWR'],\n",
       " ['01101404', '4', '546', 'MCI', 'DTW'],\n",
       " ['01091755', '28', '1086', 'ORD', 'SLC'],\n",
       " ['02191325', '-6', '650', 'BIL', 'MSP'],\n",
       " ['02251220', '10', '504', 'DAL', 'ABQ'],\n",
       " ['02061630', '-4', '943', 'DAY', 'DEN'],\n",
       " ['02181246', '-1', '111', 'IAH', 'LCH'],\n",
       " ['02101034', '-2', '1953', 'JFK', 'LAS'],\n",
       " ['02180707', '3', '274', 'ORD', 'CLE'],\n",
       " ['02201155', '-5', '214', 'SAT', 'DFW'],\n",
       " ['03091850', '-3', '822', 'BOS', 'ATL'],\n",
       " ['03211450', '0', '922', 'DFW', 'RDU'],\n",
       " ['03251045', '-3', '789', 'SEA', 'SBA'],\n",
       " ['03301330', '-6', '293', 'SFO', 'LAX']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.sample(False, 0.00001, 123).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleN = round(flights.count()*0.00001)\n",
    "sampleN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['03211450', '0', '922', 'DFW', 'RDU'],\n",
       " ['03301500', '-6', '389', 'MSP', 'STL'],\n",
       " ['02251220', '10', '504', 'DAL', 'ABQ'],\n",
       " ['02041345', '26', '260', 'ORD', 'DSM'],\n",
       " ['03100600', '-4', '477', 'BDL', 'DTW'],\n",
       " ['03082025', '-19', '710', 'BUR', 'PDX'],\n",
       " ['01101404', '4', '546', 'MCI', 'DTW'],\n",
       " ['02191325', '-6', '650', 'BIL', 'MSP'],\n",
       " ['01241640', '183', '1511', 'ORD', 'PDX'],\n",
       " ['02120835', '2', '297', 'SJC', 'SNA'],\n",
       " ['02181246', '-1', '111', 'IAH', 'LCH'],\n",
       " ['02061630', '-4', '943', 'DAY', 'DEN'],\n",
       " ['01191615', '3', '678', 'ATL', 'HPN'],\n",
       " ['03200830', '31', '2151', 'LAX', 'JFK']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.takeSample(False, sampleN, 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why these two methods return different results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DFW',\n",
       " 'MSP',\n",
       " 'DAL',\n",
       " 'ORD',\n",
       " 'BDL',\n",
       " 'BUR',\n",
       " 'MCI',\n",
       " 'BIL',\n",
       " 'ORD',\n",
       " 'SJC',\n",
       " 'IAH',\n",
       " 'DAY',\n",
       " 'ATL',\n",
       " 'LAX']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.map(lambda x: x[3]).takeSample(False, sampleN, 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get partitions\n",
    "Get number of partitions for flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparation \n",
    "Reparation flights into 8 partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_repart = flights.repartition(8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_repart.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zipWithIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View row with index\n",
    "View each row within RDD plus its index. (hint: use zipWithIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['date', 'delay', 'distance', 'origin', 'destination'], 0),\n",
       " (['01011245', '6', '602', 'ABE', 'ATL'], 1),\n",
       " (['01020600', '-8', '369', 'ABE', 'DTW'], 2),\n",
       " (['01021245', '-2', '602', 'ABE', 'ATL'], 3),\n",
       " (['01020605', '-4', '602', 'ABE', 'ATL'], 4),\n",
       " (['01031245', '-4', '602', 'ABE', 'ATL'], 5),\n",
       " (['01030605', '0', '602', 'ABE', 'ATL'], 6),\n",
       " (['01041243', '10', '602', 'ABE', 'ATL'], 7),\n",
       " (['01040605', '28', '602', 'ABE', 'ATL'], 8),\n",
       " (['01051245', '88', '602', 'ABE', 'ATL'], 9)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_idx = flights.zipWithIndex()\n",
    "flights_idx.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove header\n",
    "Come up with a way to remove the header row in your Rdd (again ZipWithIndex is helpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['01011245', '6', '602', 'ABE', 'ATL'], 1),\n",
       " (['01020600', '-8', '369', 'ABE', 'DTW'], 2),\n",
       " (['01021245', '-2', '602', 'ABE', 'ATL'], 3),\n",
       " (['01020605', '-4', '602', 'ABE', 'ATL'], 4),\n",
       " (['01031245', '-4', '602', 'ABE', 'ATL'], 5),\n",
       " (['01030605', '0', '602', 'ABE', 'ATL'], 6),\n",
       " (['01041243', '10', '602', 'ABE', 'ATL'], 7),\n",
       " (['01040605', '28', '602', 'ABE', 'ATL'], 8),\n",
       " (['01051245', '88', '602', 'ABE', 'ATL'], 9),\n",
       " (['01050605', '9', '602', 'ABE', 'ATL'], 10)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_idx.filter(lambda x: x[1] > 0).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by (reduceByKey) \n",
    "Determine delays by originating city and sort the cities (hint: reduceByKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.csdn.net/zongzhiyuan/article/details/49965021\n",
    "delay_origin = flights_idx.filter(lambda x: x[1] > 0)\\\n",
    "        .map(lambda row: [row[0][3], int(row[0][1])])\\\n",
    "        .reduceByKey(lambda x, y: x+y).sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ABE', 5113),\n",
       " ('ABI', 5128),\n",
       " ('ABQ', 64422),\n",
       " ('ABY', 1554),\n",
       " ('ACT', 392),\n",
       " ('ACV', 8429),\n",
       " ('ADQ', -254),\n",
       " ('AEX', 10193),\n",
       " ('AGS', 5003),\n",
       " ('ALB', 22362)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_origin.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join\n",
    "Execute inner join between flights data and airport codes from our session call the dataset Joined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodesNA = sc.textFile('data/airport-codes-na.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['City', 'State', 'Country', 'IATA'],\n",
       " ['Abbotsford', 'BC', 'Canada', 'YXX'],\n",
       " ['Aberdeen', 'SD', 'USA', 'ABR'],\n",
       " ['Abilene', 'TX', 'USA', 'ABI'],\n",
       " ['Akron', 'OH', 'USA', 'CAK'],\n",
       " ['Alamosa', 'CO', 'USA', 'ALS'],\n",
       " ['Albany', 'GA', 'USA', 'ABY'],\n",
       " ['Albany', 'NY', 'USA', 'ALB'],\n",
       " ['Albuquerque', 'NM', 'USA', 'ABQ'],\n",
       " ['Alexandria', 'LA', 'USA', 'AEX']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airportCodesNA = airportCodesNA.map(lambda element: element.split('\\t'))\n",
    "airportCodesNA.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df method\n",
    "# https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=join\n",
    "# https://www.tutorialspoint.com/pyspark/pyspark_rdd.htm\n",
    "# df1 = spark.createDataFrame(airportCodesNA, schema=['City', 'State', 'Country', 'origin'])\n",
    "# df2 = spark.createDataFrame(flights, schema=['date', 'delay', 'distance', 'IATA', 'destination'])\n",
    "# Joined_data = df1.join(df2, df2.IATA == df1.origin, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Join by keys\n",
    "d1 = flights.map(lambda row: (row[3], row[:2]))\n",
    "d2 = airportCodesNA.map(lambda row: (row[3], row[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ABE', (['01011245', '6'], ['Allentown', 'PA'])),\n",
       " ('ABE', (['01020600', '-8'], ['Allentown', 'PA'])),\n",
       " ('ABE', (['01021245', '-2'], ['Allentown', 'PA'])),\n",
       " ('ABE', (['01020605', '-4'], ['Allentown', 'PA'])),\n",
       " ('ABE', (['01031245', '-4'], ['Allentown', 'PA']))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data = d1.join(d2)\n",
    "joined_data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union\n",
    "In the joined_data filter all the rows from “WA” state and separately filter all the rows from “BC” states and union them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = joined_data.filter(lambda row: row[1][1][1] == 'WA')\n",
    "b = joined_data.filter(lambda row: row[1][1][1] == 'BC')\n",
    "union_ab = a.union(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SEA', (['01011425', '92'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01010715', '-7'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01010830', '-5'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01012205', '-3'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01010600', '-3'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01012320', '1'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01010820', '-10'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01010710', '-6'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01011115', '-2'], ['Seattle', 'WA'])),\n",
       " ('SEA', (['01011205', '-3'], ['Seattle', 'WA']))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_ab.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark_3.7",
   "language": "python",
   "name": "pyspark_3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
